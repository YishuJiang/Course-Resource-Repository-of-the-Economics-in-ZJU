\chapter{重要数据特征}
本章主要关注一些重要的数据特征,比如期望、方差、协方差等,包括他们的计算、性质.

引入数学期望的一个动机是,已知概率分布,我们需要一个量来反映随机变量的平均取值.很自然地,如果一个随机变量取某一个值的概率更大,
那么这个取值在平均量中产生的作用更大,于是,用概率去做加权平均不失为一种好办法.

在此基础上,我们再引入方差,用以度量随机变量的分布对平均值的靠近程度,即其在平均值周围分布的稀疏程度.很自然的,我们会考虑$|X-\mu|$也就是“距离”去和概率加权,
但这样就会有一个问题:绝对值函数存在不可微的情形,而二次函数是处处可微又保持非负的,故而我们用$(X-\mu)^2$去和概率加权平均来定义方差.

\section{数学期望与方差}
\begin{definition}{离散型随机变量的期望}{}
    若$X$为离散型随机变量,概率分布为$\mathbb{P}(X=x_j)=p_j,j=1,2,\cdots$.如果
    $$\sum_{j}\left|x_j\right|p_j$$
    收敛,则称数学期望存在,且数学期望$\mathbb{E}X=\sum_{j}x_jp_j$.
\end{definition}
\begin{definition}{连续型随机向量的期望}{}
    若$X$为连续型随机变量,密度为$f(x)$.如果
    $$\int_{-\infty}^{+\infty}|x|f(x){\rm d}x$$
    收敛,则称数学期望存在,且数学期望$\mathbb{E}X=\int_{-\infty}^{\infty}xf(x){\rm d}x$.
\end{definition}
需要特别注意的是,这里要用到级数/积分的绝对收敛,这是为了保证,任意两项交换次序,并不会影响数学期望的结果,从而保证如果数学期望存在,则一定是唯一的.

以下是一些常见分布的数学期望.
\begin{enumerate}
    \item $X\sim B(1,p)$,$\mathbb{E}X=p$
    \item $X\sim B(n,p)$,$\mathbb{E}X=np$
    \item $X\sim P(\lambda)$,$\mathbb{E}X=\lambda$
    \item $X\sim G(p)$,$\mathbb{E}X=\frac{1}{p}$
    \item $X\sim Pas(r,p)$,$\mathbb{E}X=\frac{r}{p}$
    \item $X\sim H(n,M,N)$,$\mathbb{E}X=n\frac{M}{N}$
    \item $X\sim U(a,b)$,$\mathbb{E}X=\frac{a+b}{2}$
    \item $X\sim \epsilon(\lambda)$,$\mathbb{E}X=\frac{1}{\lambda}$
    \item $X\sim N(\mu,\sigma^2)$,$\mathbb{E}X=\mu$
    \item $X\sim \Gamma(\alpha,\beta),\mathbb{E}X=\frac{\alpha}{\beta}$
\end{enumerate}
具体计算的过程如下:
\begin{enumerate}
    \item 显然
    \item 
\end{enumerate}

\begin{definition}{随机变量的方差与标准差}{}
    若随机变量$X$的数学期望$\mu$存在且有限,则$Var X=\mathbb{E}(X-\mu)^2$称为$X$的方差,也可以记为$\mathbb{D}X$或者$\sigma_{XX}$.

    若方差有限,则$\sigma_X=\sqrt{VarX}$称为$X$的标准差.
\end{definition}
利用数学期望的线性性质,可以得到
$$\mathbb{E}(X-\mu)^2=\mathbb{E}(X^2-2\mu X+\mu^2)=\mathbb{E}X^2-2\mu\mathbb{E}X+\mu^2=\mathbb{E}X^2-(\mathbb{E}X)^2$$
这是随机变量的期望与方差之间的关系(可以运用到计算当中,但因为还要另求$Y=X^2$的期望,其实很繁琐,在下一节当中会介绍更加简洁有效的方法).

以下是一些常见分布的方差
\begin{enumerate}
    \item $X\sim B(1,p)$,$Var X=p(1-p)$
    \item $X\sim B(n,p)$,$Var X=np(1-p)$
    \item $X\sim P(\lambda)$,$Var X=\lambda$
    \item $X\sim G(p)$,$Var X=\frac{1-p}{p^2}$
    \item $X\sim Pas(r,p)$,$Var X=r\frac{1-p}{p^2}$
    \item $X\sim H(n,M,N)$,$Var X=n\frac{M}{N}\left(1-\frac{M}{N}\right)\frac{N-n}{N-1}$
    \item $X\sim U(a,b)$,$Var X=\frac{(b-a)^2}{12}$
    \item $X\sim \epsilon(\lambda)$,$Var X=\frac{1}{\lambda^2}$
    \item $X\sim N(\mu,\sigma^2)$,$Var X=\sigma^2$
    \item $X\sim \Gamma(\alpha,\beta)$,$Var X=\frac{\alpha}{\beta^2}$
\end{enumerate}
\section{数学期望与方差的性质}
首先给出一种更加便捷的数学期望的计算方法,不加证明地给出期望公式.
\begin{theorem}{期望公式}
    $(X,Y)$为随机向量,$g:\mathbb{R}^2\to \mathbb{R}$,有$Z=g(X,Y)$.

    若随机向量为离散型的,有分布列$\mathbb{P}(X=x_i,Y=y_j)=p_{ij}$,则 
    $$\mathbb{E}Z=\mathbb{E}g(X,Y)=\sum_{i,j}p_{ij}g(x_i,y_j)$$

    若随机向量为连续型的,有联合密度$f(x,y)$,则
    $$\mathbb{E}Z=\mathbb{E}g(X,Y)=\int\int_{\mathbb{R}^2}g(x,y)f(x,y){\rm d}x{\rm d}y$$
\end{theorem}
简单来说,就是将随机变量的函数看成一个整体对原先的概率做加权平均即可.于是,如果$X$是连续型随机变量,有密度函数$f(x)$,则要求$\mathbb{E}X^2$即求
$$\int_{-\infty}^{+\infty}x^2f(x){\rm d}x$$

特别的,这里并不要求$g(x,y)$要显式地含有$x,y$.例如已知$(X,Y)$的联合密度函数为$f(x,y)$,现在要求$\mathbb{E}X$,只需要求
$$\int\int_{\mathbb{R}^2}xf(x,y){\rm d}x{\rm d}y$$
这比先求边缘分布$f_X(x)$再求$\mathbb{E}X$要方便地多.
\begin{example}
    $X,Y$独立,且均服从标准正态分布,$Z=(X^2+Y^2)^\alpha,\alpha>-1$,求$\mathbb{E}Z$.
\end{example}
{\fangsong 
    
由连续型随机向量各分量独立的充要条件,$f(x,y)=f_X(x)f_Y(y)=\frac{1}{2\pi}{\rm e}^{-\frac{x^2+y^2}{2}}$为联合密度.

由期望公式,$\mathbb{E}Z=\int\int_{\mathbb{R}^2}f(x,y)(x^2+y^2)^\alpha {\rm d}x{\rm d}y=\frac{1}{2\pi}\int\int_{\mathbb{R}^2}(x^2+y^2)^\alpha {\rm e}^{-\frac{x^2+y^2}{2}}{\rm d}x{\rm d}y$

考虑换元:$x=r\sin\theta,y=r\cos\theta,r:0\to +\infty,\theta:0\to 2\pi $
}
数学期望还有一大重要的性质：\textbf{将事件的示性函数与概率联系在一起}.
考虑$I_A(\omega)=\left\{\begin{aligned}1,\omega\in A\\0,\omega \notin A\end{aligned}\right.$,可以发现示性函数实际上是一个取值为$\{0,1\}$的随机变量.
对它求期望,有$\mathbb{E}(I_A)=\mathbb{P}(A)$,也就是说,事件$A$的示性函数的期望即事件$A$发生的概率.由这一条性质,我们可以得到很多公式和不等式.
\begin{theorem}{超几何分布的数学期望}{}
    $X\sim H(n,M,N)$,其实际模型为$N$个产品,其中$M$个为次品,从中任取$n$个.$X$为这$n$个中的次品数.则$\mathbb{E}X=n\frac{M}{N}$.
\end{theorem}
\begin{proof}
    定义一列用以示性的随机变量列.令$\xi_i=\left\{\begin{aligned}&1,i\ is \ bag \ goods\\ &0,i\ is\ good\ goods\end{aligned}\right.,i=1,2,\cdots,n$.
    则$X=\xi_1+\xi_2+\cdots+\xi_n$,由数学期望的线性性质,得$\mathbb{E}X=\sum_{i=1}^n\xi_i$.\\
    由于不放回的抽取,有超几何分布的性质可知$\mathbb{P}(\xi_i=1)=\frac{M}{N}$,则$\xi_i=\frac{M}{N},i=1,2,\cdots,n$.
    于是$\mathbb{E}X=n\frac{M}{N}$.
\end{proof}
\begin{proposition}{信封匹配问题}{}
    将$n$封不同信封放入$n$个不同信封,每封信有且只有一个信封与其匹配,求正确匹配信的平均数量.
\end{proposition}
\begin{proof}
    同样地,采取与上面同样的定义一列随机变量的方法.\\
    假设$X$为正确匹配的信的数量.令$\xi_i=\left\{\begin{aligned}&1,i\ is\ right\\ &0,i\ is\ not\ right\end{aligned}\right.$
    则$X=\xi_1+\xi_2+\cdots+\xi_n$,由数学期望的线性性质:$\mathbb{E}X=\sum_{i=1}^{n}\mathbb{E}\xi_i$.\\
    而$\mathbb{P}(\xi_i=1)=\frac{(n-1)!}{n!}=\frac{1}{n}$.故而$\mathbb{E}\xi_i=\frac{1}{n},i=1,2,\cdots,n$.\\
    故$\mathbb{E}X=1$.
\end{proof}
\begin{theorem}{Jordan公式}{}
    设$A_1,\cdots,A_n$均为事件,则
    $$\mathbb{P}\left(\bigcup_{i=1}^nA_i\right)=\sum_{k=1}^n(-1)^{k-1}\sum_{1\leq j_1<j_2<\cdots<j_k\leq k}\mathbb{P}(A_{j_1}A_{j_2}\cdots A_{j_k})$$
\end{theorem}
\begin{proof}
    设$I[A_i]$表示事件$A_i$的示性函数,有$I[\overline{A_i}]=1-I[A_i]$和$I[A_iA_j]=I[A_i]I[A_j]$.于是有
    $$I\left[\bigcup_{i=1}^nA_i\right]=1-I\left[\bigcap_{i=1}^n\overline{A_i}\right]
    =1-\prod _{i=1}^n I\left[\overline{A_i}\right]
    =1-\prod _{i=1}^n \left(1-I\left[A_i\right]\right)
    =\sum_{k=1}^n(-1)^{k-1}\sum_{1\leq j_1<j_2<\cdots<j_k\leq k}I\left[A_{j_1}A_{j_2}\cdots A_{j_k}\right]$$
    两边同求期望,由数学期望的线性性质,得Jordan公式.
\end{proof}
\begin{theorem}{Markov不等式}{}
    $X$为随机变量,满足$\mathbb{P}(X\geq 0)=1$(即$X\leq 0 a.s.$),则$\forall c>0,\alpha>0,\mathbb{P}(X\geq c)\leq\frac{\mathbb{E}X^\alpha}{c^\alpha}$
\end{theorem}
\begin{proof}
    考虑$I\left[X\geq c\right]$:当且仅当$X\geq c$时其值为1.\\
    于是有$I[X\geq c]\leq 1\leq\frac{X^\alpha}{c^\alpha}$.\\
    对两边同时求期望,得$\mathbb{P}(X\geq c)\leq \frac{\mathbb{E}X^\alpha}{c^\alpha}$.
\end{proof}
事实上,这是一个很松的不等式,但由于它需要的条件相当少,它依然成为了概率论中应用最广泛、最重要的不等式之一.
特别地,令$\alpha=2$,并用$|X-\mathbb{E}X|$替换$X$,得到Chebyshev不等式
\begin{theorem}{Chebyshev不等式}{}
    $\forall c>0$,$\mathbb{P}(|X-\mathbb{E}X|\geq c)\leq\frac{VarX}{c^2}$
\end{theorem}
接着再来看一个更加复杂一点的例子.
\begin{example}
    \textbf{(2019丘赛决赛)}设$A,B$为任意事件, 证明$\mathbb{P}(A\cup B)\mathbb{P}(A\cap B)\leq \mathbb{P}(A)\mathbb{P}(B)$.
\end{example}
\begin{proof}
    \textbf{思路}: 对于集合的问题, 我们所能用到的处理工具是比较少的, 但通过引入示性函数的办法, 可以将集合问题转换成研究函数的问题, 进而利用数学期望与示性函数之间的关系, 转换成\textbf{积分不等式的估计问题}.\\
    \textbf{解答}: 引入示性函数$I_A,I_B$, 有:
    $$I_{A\cap B}=I_AI_B$$
    $$I_{A\cup B}=I_A+I_B-I_AI_B$$
    等价于证明:
    $$\mathbb{E}(I_A+I_B-I_AI_B)\mathbb{E}(I_AI_B)\leq \mathbb{E}(I_A)\mathbb{E}(I_B)$$
    再利用数学期望的线性性质, 整理得到:
    $$\mathbb{E}(I_A(I_B-1))\mathbb{E}(I_B(I_A-1))\geq 0$$
    而示性函数的取值只有0,1. 故上式显然成立.
\end{proof}
\section{协方差、相关系数}

\section{条件数学期望}
